{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57d50e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alira\\anaconda3\\envs\\sorbonne\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.dataclasses import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c7d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013e527",
   "metadata": {},
   "source": [
    "# Document Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fc4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1864e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        content=\"Artificial intelligence is transforming healthcare and finance.\",\n",
    "        meta={\"lang\": \"en\", \"source\": \"test_en_1\"}\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø·Ø¨ ÙˆØ§Ù„ØªÙ…ÙˆÙŠÙ„ Ø¨Ø´ÙƒÙ„ Ø¬Ø°Ø±ÙŠ.\",\n",
    "        meta={\"lang\": \"ar\", \"source\": \"test_ar_1\"}\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"Machine learning is a subset of artificial intelligence.\",\n",
    "        meta={\"lang\": \"en\", \"source\": \"test_en_2\"}\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\",\n",
    "        meta={\"lang\": \"ar\", \"source\": \"test_ar_2\"}\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6546a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DocumentSplitter(\n",
    "    split_by=\"sentence\",\n",
    "    split_length=5,\n",
    "    split_overlap=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fde79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 1092.90it/s, Materializing param=pooler.dense.weight]                              \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: intfloat/multilingual-e5-small\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"intfloat/multilingual-e5-small\",\n",
    "    prefix=\"passage: \"\n",
    ")\n",
    "document_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3d0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = DocumentWriter(document_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a009ce34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000001428B1F3EC0>\n",
       "ðŸš… Components\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: SentenceTransformersDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - splitter.documents -> embedder.documents (list[Document])\n",
       "  - embedder.documents -> writer.documents (list[Document])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingestion_pipeline = Pipeline()\n",
    "ingestion_pipeline.add_component(\"splitter\", splitter)\n",
    "ingestion_pipeline.add_component(\"embedder\", document_embedder)\n",
    "ingestion_pipeline.add_component(\"writer\", writer)\n",
    "\n",
    "ingestion_pipeline.connect(\"splitter\", \"embedder\")\n",
    "ingestion_pipeline.connect(\"embedder\", \"writer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cb9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(content=\"Artificial intelligence is transforming healthcare.\"),\n",
    "    Document(content=\"Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ù…Ø¬Ø§Ù„ Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©.\"),\n",
    "    Document(content=\"Machine learning is a subset of AI.\"),\n",
    "    Document(content=\"ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b94a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 4}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingestion_pipeline.run({\n",
    "    \"splitter\": {\n",
    "        \"documents\": documents\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4f185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " [0.04796324670314789,\n",
       "  0.01804913952946663,\n",
       "  -0.05176614969968796,\n",
       "  -0.06620220839977264,\n",
       "  0.09119812399148941,\n",
       "  0.019064277410507202,\n",
       "  0.03561483323574066,\n",
       "  0.022805247455835342,\n",
       "  0.023575637489557266,\n",
       "  0.015585825778543949,\n",
       "  0.04074416682124138,\n",
       "  0.02897908352315426,\n",
       "  0.08362524956464767,\n",
       "  -0.055478788912296295,\n",
       "  -0.03767363727092743,\n",
       "  0.03409387543797493,\n",
       "  0.10263031721115112,\n",
       "  -0.05481068789958954,\n",
       "  -0.05244922637939453,\n",
       "  -0.04326128959655762,\n",
       "  -0.030443893745541573,\n",
       "  -0.017666863277554512,\n",
       "  -0.0614592470228672,\n",
       "  0.08487307280302048,\n",
       "  0.06706401705741882,\n",
       "  0.06405425071716309,\n",
       "  -0.02701205387711525,\n",
       "  -0.004717334173619747,\n",
       "  0.02177138440310955,\n",
       "  -0.04302538186311722,\n",
       "  -0.06790175288915634,\n",
       "  -0.06638488918542862,\n",
       "  0.043984729796648026,\n",
       "  -0.0707896500825882,\n",
       "  0.024574195966124535,\n",
       "  0.06187838688492775,\n",
       "  -0.09372556954622269,\n",
       "  -0.09639187902212143,\n",
       "  0.06050123646855354,\n",
       "  -0.09267812967300415,\n",
       "  -0.03745802491903305,\n",
       "  -0.037600062787532806,\n",
       "  0.04414338245987892,\n",
       "  0.07088519632816315,\n",
       "  0.03739657625555992,\n",
       "  -0.021897656843066216,\n",
       "  -0.039920445531606674,\n",
       "  0.03817501664161682,\n",
       "  -0.09676199406385422,\n",
       "  -0.059297993779182434,\n",
       "  -0.0983404889702797,\n",
       "  0.06980650126934052,\n",
       "  0.024138500913977623,\n",
       "  0.08093760162591934,\n",
       "  0.013526475988328457,\n",
       "  -0.07903698086738586,\n",
       "  -0.07839265465736389,\n",
       "  -0.0668577253818512,\n",
       "  -0.07076169550418854,\n",
       "  0.000336680852342397,\n",
       "  0.04405452311038971,\n",
       "  -0.024646194651722908,\n",
       "  -0.0005053050699643791,\n",
       "  0.05242467671632767,\n",
       "  0.08838903158903122,\n",
       "  0.009595819748938084,\n",
       "  0.03918198496103287,\n",
       "  0.052293986082077026,\n",
       "  -0.0422341488301754,\n",
       "  -0.04506739601492882,\n",
       "  -0.04951408505439758,\n",
       "  0.08524428308010101,\n",
       "  -0.0010688803158700466,\n",
       "  -0.04333006590604782,\n",
       "  0.052455708384513855,\n",
       "  0.08326709270477295,\n",
       "  0.05089486017823219,\n",
       "  -0.07501494139432907,\n",
       "  0.02281499095261097,\n",
       "  -0.015053072944283485,\n",
       "  -0.052023667842149734,\n",
       "  -0.052525389939546585,\n",
       "  -0.021799104288220406,\n",
       "  0.03537191450595856,\n",
       "  -0.05605880916118622,\n",
       "  0.05282149836421013,\n",
       "  0.05493655055761337,\n",
       "  -0.04076321795582771,\n",
       "  0.07519326359033585,\n",
       "  -0.056979309767484665,\n",
       "  0.04704965651035309,\n",
       "  0.00531694246456027,\n",
       "  -0.10427181422710419,\n",
       "  -0.03118910640478134,\n",
       "  -0.07134498655796051,\n",
       "  -0.06367887556552887,\n",
       "  -0.08731698244810104,\n",
       "  0.07766956090927124,\n",
       "  0.07015162706375122,\n",
       "  -0.047993190586566925,\n",
       "  0.02014751173555851,\n",
       "  0.007637289352715015,\n",
       "  0.05273154377937317,\n",
       "  -0.11777601391077042,\n",
       "  -0.04767568036913872,\n",
       "  0.053258609026670456,\n",
       "  0.05660083517432213,\n",
       "  -0.04508037120103836,\n",
       "  0.049421824514865875,\n",
       "  -0.09229227155447006,\n",
       "  -0.022856907919049263,\n",
       "  0.05246511474251747,\n",
       "  0.08106230199337006,\n",
       "  -0.006957284174859524,\n",
       "  -0.09441468864679337,\n",
       "  -0.021748552098870277,\n",
       "  -0.03100731410086155,\n",
       "  -0.04261350259184837,\n",
       "  0.0580405555665493,\n",
       "  -0.06468474119901657,\n",
       "  0.05716182291507721,\n",
       "  0.025127528235316277,\n",
       "  -0.04912860691547394,\n",
       "  -0.04714113846421242,\n",
       "  -0.0686006024479866,\n",
       "  -0.03926917910575867,\n",
       "  0.051668617874383926,\n",
       "  0.05283396691083908,\n",
       "  0.08395244181156158,\n",
       "  0.027267731726169586,\n",
       "  0.06138726696372032,\n",
       "  0.041475504636764526,\n",
       "  0.025180799886584282,\n",
       "  0.04432487115263939,\n",
       "  0.03676746040582657,\n",
       "  0.10899516195058823,\n",
       "  -0.020839044824242592,\n",
       "  -0.012200075201690197,\n",
       "  0.007122796028852463,\n",
       "  -0.02241167053580284,\n",
       "  -0.021429359912872314,\n",
       "  0.07766097038984299,\n",
       "  -0.0348527692258358,\n",
       "  0.023411238566040993,\n",
       "  0.05803249776363373,\n",
       "  0.047112129628658295,\n",
       "  0.06057409569621086,\n",
       "  -0.08599044382572174,\n",
       "  0.0639263466000557,\n",
       "  -0.055435702204704285,\n",
       "  0.08119293302297592,\n",
       "  0.028202395886182785,\n",
       "  0.04081212729215622,\n",
       "  0.00867738202214241,\n",
       "  0.10312528163194656,\n",
       "  -0.022603334859013557,\n",
       "  -0.058159589767456055,\n",
       "  -0.025077275931835175,\n",
       "  0.03823831304907799,\n",
       "  0.04840522259473801,\n",
       "  -0.017634162679314613,\n",
       "  0.006423352751880884,\n",
       "  -0.06392884254455566,\n",
       "  -0.01909499056637287,\n",
       "  -0.04694085195660591,\n",
       "  -0.027709944173693657,\n",
       "  0.028504643589258194,\n",
       "  0.06067217141389847,\n",
       "  -0.09270332753658295,\n",
       "  -0.04221289977431297,\n",
       "  -0.07155926525592804,\n",
       "  0.0229409821331501,\n",
       "  0.019998854026198387,\n",
       "  0.05752266198396683,\n",
       "  -0.020190740004181862,\n",
       "  0.02531490847468376,\n",
       "  -0.031614527106285095,\n",
       "  0.05760783329606056,\n",
       "  -0.0009969882667064667,\n",
       "  0.01564990170300007,\n",
       "  -0.044442515820264816,\n",
       "  -0.05623501539230347,\n",
       "  -0.04270881414413452,\n",
       "  -0.03799550607800484,\n",
       "  -0.09160806983709335,\n",
       "  -0.05660571902990341,\n",
       "  -0.08700384944677353,\n",
       "  0.03898487240076065,\n",
       "  -0.022321907803416252,\n",
       "  -0.056086018681526184,\n",
       "  0.07729608565568924,\n",
       "  0.006255537271499634,\n",
       "  -0.051238786429166794,\n",
       "  -0.09996947646141052,\n",
       "  -0.04713253676891327,\n",
       "  0.05146396905183792,\n",
       "  -0.04976147413253784,\n",
       "  0.034907933324575424,\n",
       "  0.07349587231874466,\n",
       "  0.03200775012373924,\n",
       "  0.0027332932222634554,\n",
       "  -0.05563075840473175,\n",
       "  0.022983694449067116,\n",
       "  -0.00419631227850914,\n",
       "  0.04189348220825195,\n",
       "  -0.010617709718644619,\n",
       "  -0.036603737622499466,\n",
       "  0.06605348736047745,\n",
       "  -0.018524838611483574,\n",
       "  0.048227690160274506,\n",
       "  0.03554660081863403,\n",
       "  -0.06234321370720863,\n",
       "  -0.0431363545358181,\n",
       "  0.046263355761766434,\n",
       "  -0.008176092058420181,\n",
       "  -0.031726617366075516,\n",
       "  0.03105258196592331,\n",
       "  0.08105144649744034,\n",
       "  -0.036736395210027695,\n",
       "  -0.01949324645102024,\n",
       "  0.047270793467760086,\n",
       "  -0.02692899852991104,\n",
       "  0.012323050759732723,\n",
       "  -0.03953488543629646,\n",
       "  -0.019551828503608704,\n",
       "  0.05162912979722023,\n",
       "  0.0923713967204094,\n",
       "  -0.09418956935405731,\n",
       "  -0.06641972810029984,\n",
       "  0.03963610529899597,\n",
       "  -0.011483637616038322,\n",
       "  -0.0008957443060353398,\n",
       "  -0.0929393619298935,\n",
       "  -0.07599861174821854,\n",
       "  -0.053932901471853256,\n",
       "  -0.06553032249212265,\n",
       "  -0.0009421109571121633,\n",
       "  0.0027973330579698086,\n",
       "  0.03814079239964485,\n",
       "  -0.011862300336360931,\n",
       "  -0.033471301198005676,\n",
       "  -0.05705563351511955,\n",
       "  0.019200894981622696,\n",
       "  -0.02633333019912243,\n",
       "  0.04322332143783569,\n",
       "  -0.004035121761262417,\n",
       "  -0.053835250437259674,\n",
       "  -0.027610596269369125,\n",
       "  0.012027844786643982,\n",
       "  0.06896524131298065,\n",
       "  0.01190735399723053,\n",
       "  -0.07123325765132904,\n",
       "  -0.027400149032473564,\n",
       "  -0.053658049553632736,\n",
       "  -0.022896530106663704,\n",
       "  0.01995248906314373,\n",
       "  0.06303907930850983,\n",
       "  0.04030740633606911,\n",
       "  -0.023831643164157867,\n",
       "  -0.0032923887483775616,\n",
       "  0.07969705760478973,\n",
       "  -0.026925193145871162,\n",
       "  0.03212693706154823,\n",
       "  0.07329010963439941,\n",
       "  0.09220928698778152,\n",
       "  0.06117349863052368,\n",
       "  -0.04702802747488022,\n",
       "  -0.01486295461654663,\n",
       "  -0.09330081194639206,\n",
       "  -0.06220972165465355,\n",
       "  -0.0629458948969841,\n",
       "  0.00868118554353714,\n",
       "  0.00604210002347827,\n",
       "  -0.07272489368915558,\n",
       "  -0.025198670104146004,\n",
       "  -0.06489622592926025,\n",
       "  0.03051677532494068,\n",
       "  0.06626886874437332,\n",
       "  -0.045404378324747086,\n",
       "  -0.0593816414475441,\n",
       "  0.05662677064538002,\n",
       "  0.03750883787870407,\n",
       "  0.040709931403398514,\n",
       "  0.004976024851202965,\n",
       "  0.05232580378651619,\n",
       "  -0.02641049027442932,\n",
       "  -0.007058130577206612,\n",
       "  0.059976983815431595,\n",
       "  -0.05196944251656532,\n",
       "  -0.0737486481666565,\n",
       "  -0.029775619506835938,\n",
       "  -0.03621665760874748,\n",
       "  -0.024873636662960052,\n",
       "  -0.02420923486351967,\n",
       "  0.06571647524833679,\n",
       "  0.03773460164666176,\n",
       "  0.03695371374487877,\n",
       "  -0.0016592619940638542,\n",
       "  -0.06668423861265182,\n",
       "  0.05716042220592499,\n",
       "  0.015830928459763527,\n",
       "  -0.034904904663562775,\n",
       "  0.0299253948032856,\n",
       "  0.05607389286160469,\n",
       "  -0.053677696734666824,\n",
       "  0.0430540032684803,\n",
       "  0.013665322214365005,\n",
       "  0.08837217837572098,\n",
       "  0.002688019070774317,\n",
       "  -0.015177046880126,\n",
       "  0.043333739042282104,\n",
       "  0.043401360511779785,\n",
       "  -0.056982532143592834,\n",
       "  -0.013736949302256107,\n",
       "  0.047951847314834595,\n",
       "  0.07695722579956055,\n",
       "  0.0008741439087316394,\n",
       "  0.01001023780554533,\n",
       "  -0.03589675948023796,\n",
       "  -0.06107394024729729,\n",
       "  -0.057250652462244034,\n",
       "  -0.04976847022771835,\n",
       "  -0.005895017180591822,\n",
       "  -0.01028802152723074,\n",
       "  0.012840586714446545,\n",
       "  0.08591349422931671,\n",
       "  -0.07471773773431778,\n",
       "  0.006486581638455391,\n",
       "  0.06547775864601135,\n",
       "  0.04430357366800308,\n",
       "  0.012084023095667362,\n",
       "  -0.04688689485192299,\n",
       "  -0.03944055736064911,\n",
       "  0.04867583513259888,\n",
       "  -0.022616012021899223,\n",
       "  -0.04085669666528702,\n",
       "  0.0045502376742661,\n",
       "  0.020449677482247353,\n",
       "  -0.034484345465898514,\n",
       "  -0.08976790308952332,\n",
       "  0.035227369517087936,\n",
       "  0.03528886288404465,\n",
       "  -0.03321223706007004,\n",
       "  0.057410769164562225,\n",
       "  -0.012313161045312881,\n",
       "  -0.047808438539505005,\n",
       "  0.05873753875494003,\n",
       "  -0.05077969655394554,\n",
       "  -0.014102904126048088,\n",
       "  -0.012239891104400158,\n",
       "  0.03783832862973213,\n",
       "  -0.11306297034025192,\n",
       "  0.020982135087251663,\n",
       "  0.012664174661040306,\n",
       "  -0.015024250373244286,\n",
       "  0.027739306911826134,\n",
       "  -0.066652312874794,\n",
       "  0.0028971091378480196,\n",
       "  0.07033931463956833,\n",
       "  0.0698896124958992,\n",
       "  -0.039435580372810364,\n",
       "  -0.029954520985484123,\n",
       "  0.07605237513780594,\n",
       "  0.04951424151659012,\n",
       "  0.02749226987361908,\n",
       "  0.054687004536390305,\n",
       "  0.013915869407355785,\n",
       "  0.021101610735058784,\n",
       "  0.01059388555586338,\n",
       "  -0.0529482439160347,\n",
       "  0.05348264053463936,\n",
       "  0.044296592473983765,\n",
       "  -0.016798175871372223,\n",
       "  -0.030760157853364944,\n",
       "  0.04751574620604515,\n",
       "  -0.021825386211276054,\n",
       "  -0.0011215106351301074,\n",
       "  0.07098106294870377,\n",
       "  -0.02530004270374775,\n",
       "  -0.021730955690145493,\n",
       "  0.04888579994440079,\n",
       "  0.028342006728053093,\n",
       "  0.05091414228081703,\n",
       "  0.05041326582431793])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = document_store.filter_documents()\n",
    "len(docs), docs[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f5e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e9e2d",
   "metadata": {},
   "source": [
    "# 02_retrieval_quality.ipynb\n",
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371b1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8578407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"intfloat/multilingual-e5-small\",\n",
    "    prefix=\"query: \"\n",
    ")\n",
    "query_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1731542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = InMemoryEmbeddingRetriever(document_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78aa16cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x00000142901A06E0>\n",
       "ðŸš… Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (list[float])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pipeline = Pipeline()\n",
    "query_pipeline.add_component(\"embedder\", query_embedder)\n",
    "query_pipeline.add_component(\"retriever\", retriever)\n",
    "\n",
    "query_pipeline.connect(\"embedder\", \"retriever\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b92764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 43.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ù…Ø¬Ø§Ù„ Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©.\n",
      "Machine learning is a subset of AI.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = query_pipeline.run({\n",
    "    \"embedder\": {\"text\": \"Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ\"},\n",
    "    \"retriever\": {\"top_k\": 3}\n",
    "})\n",
    "\n",
    "for doc in result[\"retriever\"][\"documents\"]:\n",
    "    print(doc.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838aae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 166.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of AI.\n",
      "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\n",
      "Artificial intelligence is transforming healthcare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = query_pipeline.run({\n",
    "    \"embedder\": {\"text\": \"What is machine learning?\"},\n",
    "    \"retriever\": {\"top_k\": 3}\n",
    "})\n",
    "\n",
    "for doc in result[\"retriever\"][\"documents\"]:\n",
    "    print(doc.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a42c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 83.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ù…Ø¬Ø§Ù„ Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©.\n",
      "Machine learning is a subset of AI.\n",
      "Artificial intelligence is transforming healthcare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = query_pipeline.run({\n",
    "    \"embedder\": {\"text\": \"Explain Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\"},\n",
    "    \"retriever\": {\"top_k\": 4}\n",
    "})\n",
    "\n",
    "for doc in result[\"retriever\"][\"documents\"]:\n",
    "    print(doc.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531a5a6",
   "metadata": {},
   "source": [
    "\n",
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17856b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceLocalGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f79db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"intfloat/multilingual-e5-small\",\n",
    "    prefix=\"query: \"\n",
    ")\n",
    "rag_query_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e13c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever = InMemoryEmbeddingRetriever(document_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a72b072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Use ONLY the following documents to answer the question.\n",
    "If the answer is not present, say \"I don't know\".\n",
    "\n",
    "Documents:\n",
    "{% for doc in documents %}\n",
    "{{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ query }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6569237",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceLocalGenerator(\n",
    "    model=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    generation_kwargs={\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"temperature\": 0.2,\n",
    "        \"do_sample\": False\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accefc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineError",
     "evalue": "Component has already been added in another Pipeline. Components can't be shared between Pipelines. Create a new instance instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPipelineError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m rag_pipeline = Pipeline()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_component\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery_embedder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrag_query_embedder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m rag_pipeline.add_component(\u001b[33m\"\u001b[39m\u001b[33mretriever\u001b[39m\u001b[33m\"\u001b[39m, rag_retriever)\n\u001b[32m      5\u001b[39m rag_pipeline.add_component(\u001b[33m\"\u001b[39m\u001b[33mprompt_builder\u001b[39m\u001b[33m\"\u001b[39m, prompt_builder)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alira\\anaconda3\\envs\\sorbonne\\Lib\\site-packages\\haystack\\core\\pipeline\\base.py:367\u001b[39m, in \u001b[36mPipelineBase.add_component\u001b[39m\u001b[34m(self, name, instance)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33m__haystack_added_to_pipeline__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m     msg = (\n\u001b[32m    364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComponent has already been added in another Pipeline. Components can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be shared between Pipelines. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCreate a new instance instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    366\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineError(msg)\n\u001b[32m    369\u001b[39m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33m__haystack_added_to_pipeline__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    370\u001b[39m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33m__component_name__\u001b[39m\u001b[33m\"\u001b[39m, name)\n",
      "\u001b[31mPipelineError\u001b[39m: Component has already been added in another Pipeline. Components can't be shared between Pipelines. Create a new instance instead."
     ]
    }
   ],
   "source": [
    "rag_pipeline = Pipeline()\n",
    "\n",
    "rag_pipeline.add_component(\"query_embedder\", rag_query_embedder)\n",
    "rag_pipeline.add_component(\"retriever\", rag_retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "\n",
    "rag_pipeline.connect(\"query_embedder\", \"retriever\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a8df0a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Component named prompt_builder not found in the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mrag_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery_embedder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_builder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mllm\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mreplies\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alira\\anaconda3\\envs\\sorbonne\\Lib\\site-packages\\haystack\\core\\pipeline\\pipeline.py:251\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, data, include_outputs_from, break_point, pipeline_snapshot, snapshot_callback)\u001b[39m\n\u001b[32m    248\u001b[39m data = \u001b[38;5;28mself\u001b[39m._prepare_component_input_data(data)\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Raise ValueError if input is malformed in some way\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# We create a list of components in the pipeline sorted by name, so that the algorithm runs\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# deterministically and independent of insertion order into the pipeline.\u001b[39;00m\n\u001b[32m    255\u001b[39m ordered_component_names = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m.graph.nodes.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alira\\anaconda3\\envs\\sorbonne\\Lib\\site-packages\\haystack\\core\\pipeline\\base.py:888\u001b[39m, in \u001b[36mPipelineBase.validate_input\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m component_name, component_inputs \u001b[38;5;129;01min\u001b[39;00m data.items():\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m component_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.graph.nodes:\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComponent named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomponent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in the pipeline.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    889\u001b[39m     instance = \u001b[38;5;28mself\u001b[39m.graph.nodes[component_name][\u001b[33m\"\u001b[39m\u001b[33minstance\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    890\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m socket_name, socket \u001b[38;5;129;01min\u001b[39;00m instance.__haystack_input__._sockets_dict.items():\n",
      "\u001b[31mValueError\u001b[39m: Component named prompt_builder not found in the pipeline."
     ]
    }
   ],
   "source": [
    "result = rag_pipeline.run({\n",
    "    \"query_embedder\": {\"text\": \"Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ\"},\n",
    "    \"prompt_builder\": {\"query\": \"Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ\"}\n",
    "})\n",
    "\n",
    "print(result[\"llm\"][\"replies\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8c0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sorbonne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
